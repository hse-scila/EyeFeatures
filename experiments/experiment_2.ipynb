{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from eyefeatures.features.extractor import Extractor\n",
    "import eyefeatures.features.stats as eye_stats\n",
    "import numpy as np\n",
    "import eyefeatures.features.scanpath_dist as eye_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f541f",
   "metadata": {},
   "source": [
    "# Extraction of simple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b028aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dyslexia = pd.read_excel('Fixation_report.xlsx', sheet_name=0)\n",
    "dyslexia.Group = 2\n",
    "norm = pd.read_excel('Fixation_report.xlsx', sheet_name=1)\n",
    "norm.Group = 1\n",
    "risk = pd.read_excel('Fixation_report.xlsx', sheet_name=2)\n",
    "risk.Group = 0\n",
    "print(dyslexia.shape, norm.shape, risk.shape)\n",
    "data = pd.concat([dyslexia, norm, risk], ignore_index=True)\n",
    "data['timestamp'] = list(range(len(data)))\n",
    "data\n",
    "\n",
    "extractor = Extractor(\n",
    "    features=[                                       # list of features\n",
    "        eye_stats.SaccadeFeatures(\n",
    "            features_stats={\n",
    "                'length': ['mean', 'std', 'max', 'min', 'sum', 'count'],\n",
    "            }\n",
    "        ),\n",
    "        eye_stats.FixationFeatures(\n",
    "            features_stats={\n",
    "                'duration': ['mean', 'std', 'min', 'max', 'sum'],\n",
    "            }\n",
    "        ),\n",
    "        eye_stats.RegressionFeatures(\n",
    "            rule =  (90,),\n",
    "            deviation = 70,\n",
    "            features_stats={\n",
    "                'length': ['mean', 'std', 'max', 'min','count'],\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    ],\n",
    "    x='FIX_X',                                  # column with x-coordinate of fixations\n",
    "    y='FIX_Y',                                  # column with y-coordinate of fixations\n",
    "    duration='FIX_DURATION',                    # column with duration in ms\n",
    "    t = 'timestamp',\n",
    "    pk=['SubjectID', 'Sentence_ID'],                       # list of columns being primary key\n",
    "    return_df=True,                              # return as pd.DataFrame\n",
    "    extra=['Group'],\n",
    "    aggr_extra='mean',\n",
    "    leave_pk = True\n",
    ")\n",
    "\n",
    "simple_stats = extractor.fit_transform(data)\n",
    "\n",
    "X_train = simple_stats.drop(columns = ['Group', 'SubjectID', 'Sentence_ID'])\n",
    "y_train = simple_stats['Group'].astype(int) \n",
    "\n",
    "\n",
    "norm_demo = pd.read_excel('demo.xlsx', sheet_name=0)\n",
    "risk_demo = pd.read_excel('demo.xlsx', sheet_name=1)\n",
    "dyslexia_demo  = pd.read_excel('demo.xlsx', sheet_name=2)\n",
    "data_demo = pd.concat([dyslexia_demo, norm_demo, risk_demo], ignore_index=True).drop(columns=['Group'])\n",
    "simple_stats_demo = simple_stats.merge(data_demo, on='SubjectID')\n",
    "X_train_demo = simple_stats_demo.drop(columns = ['Group', 'SubjectID', 'Sentence_ID'])\n",
    "y_train_demo = simple_stats_demo['Group'].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b85f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "\n",
    "X_test, y_test = None, None\n",
    "\n",
    "f1_micro = make_scorer(f1_score, average=\"micro\")\n",
    "f1_micro._deprecation_msg ='xui'\n",
    "\n",
    "rf_search_space = {\n",
    "    \"n_estimators\":      Integer(100, 1000),\n",
    "    \"max_depth\":         Categorical([None] + list(range(2, 33))),\n",
    "    \"min_samples_split\": Integer(2, 20),\n",
    "    \"min_samples_leaf\":  Integer(1, 10),\n",
    "    \"max_features\":      Categorical([\"sqrt\", \"log2\", None]),\n",
    "    \"bootstrap\":         Categorical([True, False]),\n",
    "}\n",
    "\n",
    "gb_search_space = {\n",
    "    \"n_estimators\":      Integer(50, 1000),\n",
    "    \"learning_rate\":     Real(1e-3, 0.3, prior=\"log-uniform\"),\n",
    "    \"max_depth\":         Integer(1, 10),\n",
    "    \"subsample\":         Real(0.5, 1.0),\n",
    "    \"min_samples_split\": Integer(2, 20),\n",
    "    \"min_samples_leaf\":  Integer(1, 20),\n",
    "    \"max_features\":      Categorical([\"sqrt\", \"log2\", None]),\n",
    "}\n",
    "\n",
    "def bayes_search(\n",
    "    model,\n",
    "    search_space,\n",
    "    name: str,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test=None,\n",
    "    y_test=None,\n",
    "    *,\n",
    "    n_iter=64,\n",
    "    cv=10,\n",
    "    random_state=228,\n",
    "    scoring=f1_micro,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Run Bayesian hyperparameter optimization with explicit data inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator\n",
    "        Base (unfitted) sklearn estimator.\n",
    "    search_space : dict\n",
    "        skopt space definition.\n",
    "    name : str\n",
    "        Label for prints/logs.\n",
    "    X_train, y_train : array-like\n",
    "        Training data.\n",
    "    X_test, y_test : array-like, optional\n",
    "        If provided, a classification report will be printed.\n",
    "    n_iter : int\n",
    "        Number of parameter evaluations.\n",
    "    cv : int or CV splitter\n",
    "        Cross-validation strategy.\n",
    "    random_state : int\n",
    "        Seed for BayesSearchCV.\n",
    "    scoring : str or callable\n",
    "        Scoring metric.\n",
    "    verbose : int\n",
    "        Verbosity (0,1,2 like GridSearchCV).\n",
    "    n_jobs : int\n",
    "        Parallel jobs for fitting inside CV.\n",
    "    return_train_score : bool\n",
    "        If True, also returns train predictions & scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    opt : BayesSearchCV (fitted)\n",
    "    results : dict\n",
    "        Contains optional test predictions/report and optionally train predictions.\n",
    "    \"\"\"\n",
    "    opt = BayesSearchCV(\n",
    "        estimator=model,\n",
    "        search_spaces=search_space,\n",
    "        n_iter=n_iter,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        random_state=random_state,\n",
    "        verbose=verbose,\n",
    "        refit=True,\n",
    "        return_train_score=return_train_score\n",
    "    )\n",
    "    opt.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"\\n{name} best parameters → {opt.best_params_}\")\n",
    "    print(f\"{name} CV-best ({scoring if isinstance(scoring,str) else 'custom'}) → {opt.best_score_:.4f}\")\n",
    "\n",
    "    results = {\"best_estimator\": opt.best_estimator_, \"cv_best_score\": opt.best_score_}\n",
    "\n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_pred_test = opt.predict(X_test)\n",
    "        print(\"\\nTest-set report:\")\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "        results[\"y_test_pred\"] = y_pred_test\n",
    "\n",
    "    if return_train_score:\n",
    "        y_pred_train = opt.predict(X_train)\n",
    "        results[\"y_train_pred\"] = y_pred_train\n",
    "\n",
    "    return opt, results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf483623",
   "metadata": {},
   "source": [
    "# Experiments run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea57812",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt, rf_res = bayes_search(RandomForestClassifier(random_state=228),\n",
    "                               rf_search_space,\n",
    "                               \"Random Forest\",\n",
    "                               X_train, y_train, n_iter=256)\n",
    "\n",
    "gb_opt, gb_res = bayes_search(GradientBoostingClassifier(random_state=228),\n",
    "                               gb_search_space,\n",
    "                               \"Random Forest\",\n",
    "                               X_train.fillna(-10000), y_train, n_iter=256)\n",
    "\n",
    "rf_res['cv_best_score'], gb_res['cv_best_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee794ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt, rf_res = bayes_search(RandomForestClassifier(random_state=228),\n",
    "                               rf_search_space,\n",
    "                               \"Random Forest\",\n",
    "                               X_train_demo, y_train_demo, n_iter=256)\n",
    "\n",
    "gb_opt, gb_res = bayes_search(GradientBoostingClassifier(random_state=228),\n",
    "                               gb_search_space,\n",
    "                               \"Random Forest\",\n",
    "                               X_train_demo.fillna(-10000), y_train_demo, n_iter=256)\n",
    "\n",
    "rf_res['cv_best_score'], gb_res['cv_best_score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eyefeatures_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
